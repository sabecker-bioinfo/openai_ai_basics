{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c5ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb4eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The documentation suggests that the organization string is probably safe to be in the source code.\n",
    "# The key is secret and of course is not safe to include in code.\n",
    "# Both are NOT in the code for now.\n",
    "openai.organization = os.getenv(\"openapi_org\")\n",
    "openai.api_key = os.getenv(\"openapi_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd08fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are all of the models:\n",
      " ['babbage', 'ada', 'davinci', 'text-embedding-ada-002', 'babbage-code-search-code', 'text-similarity-babbage-001', 'text-davinci-001', 'curie-instruct-beta', 'babbage-code-search-text', 'babbage-similarity', 'curie-search-query', 'code-search-babbage-text-001', 'code-cushman-001', 'code-search-babbage-code-001', 'text-ada-001', 'code-davinci-002', 'text-similarity-ada-001', 'text-davinci-insert-002', 'ada-code-search-code', 'text-davinci-002', 'ada-similarity', 'code-search-ada-text-001', 'text-search-ada-query-001', 'text-curie-001', 'text-davinci-edit-001', 'davinci-search-document', 'ada-code-search-text', 'text-search-ada-doc-001', 'code-davinci-edit-001', 'davinci-instruct-beta', 'text-babbage-001', 'text-similarity-curie-001', 'code-search-ada-code-001', 'ada-search-query', 'text-search-davinci-query-001', 'curie-similarity', 'davinci-search-query', 'text-davinci-insert-001', 'babbage-search-document', 'ada-search-document', 'curie', 'text-search-babbage-doc-001', 'text-search-curie-doc-001', 'text-search-curie-query-001', 'babbage-search-query', 'text-search-davinci-doc-001', 'text-search-babbage-query-001', 'curie-search-document', 'text-similarity-davinci-001', 'audio-transcribe-001', 'text-davinci-003', 'davinci-similarity', 'cushman:2020-05-03', 'ada:2020-05-03', 'babbage:2020-05-03', 'curie:2020-05-03', 'davinci:2020-05-03', 'if-davinci-v2', 'if-curie-v2', 'if-davinci:3.0.0', 'davinci-if:3.0.0', 'davinci-instruct-beta:2.0.0', 'text-ada:001', 'text-davinci:001', 'text-curie:001', 'text-babbage:001']\n",
      "\n",
      "These models may be useful for tasks with code:\n",
      " ['babbage-code-search-code', 'babbage-code-search-text', 'code-search-babbage-text-001', 'code-cushman-001', 'code-search-babbage-code-001', 'code-davinci-002', 'ada-code-search-code', 'code-search-ada-text-001', 'ada-code-search-text', 'code-davinci-edit-001', 'code-search-ada-code-001']\n"
     ]
    }
   ],
   "source": [
    "# Probably the simplest call is to list the available models.\n",
    "openai_models = openai.Model.list()\n",
    "openai_models_json = json.loads(str(openai_models))\n",
    "openai_models_json['data'][0]\n",
    "available_models = []\n",
    "for rec in openai_models_json['data']:\n",
    "    available_models.append(rec['id'])\n",
    "print(\"Here are all of the models:\\n\", available_models)\n",
    "\n",
    "code_regex = re.compile(\"code\")\n",
    "code_models = list(filter(code_regex.search, available_models))\n",
    "print(\"\\nThese models may be useful for tasks with code:\\n\", code_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3476f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text-davinci-003']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model ids could easily be mistyped. Here is a helper function to find the closest to a user input.\n",
    "def closest_model_id(models, user_input):\n",
    "    best_guess = difflib.get_close_matches(user_input, models, cutoff=0.8, n=1)\n",
    "    return(best_guess)\n",
    "\n",
    "closest_model_id(available_models, \"text-davinci-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12fb293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " Write a paragraph explaining the history of the bioinformatics field. \n",
      "Model:\n",
      " ['text-davinci-003']\n",
      "\n",
      "Response:\n",
      " {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nBioinformatics is a relatively young field that has come about as the result of the convergence of several disciplines, including biology, computer science, mathematics, and engineering. It began in the 1970s when scientists first started to use computers to store and analyze biological data. Since then, the field has grown rapidly, as new technologies and techniques have been developed to store and analyze ever larger and more complex data sets. Today, bioinformatics is used in many fields of research, from basic research in genetics and molecular biology, to medical research, to agriculture and food production, to the development of new drugs and therapies. It is becoming increasingly important for research and development in many areas, as our understanding of the complexity of life grows.\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674247059,\n",
      "  \"id\": \"cmpl-6asQls8uJnRitUjft8Z3wTim1uNcC\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 150,\n",
      "    \"prompt_tokens\": 14,\n",
      "    \"total_tokens\": 164\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's see if the ai knows the history of the bioinformatics field.\n",
    "bioinformatics_history_prompt = \"Write a paragraph explaining the history of the bioinformatics field.\"\n",
    "bioinformatics_history_model = closest_model_id(available_models, \"text-davinci-003\")\n",
    "# TODO: determine how to pass these variables into the openai.Completion.create call\n",
    "print(\"Prompt:\\n\", bioinformatics_history_prompt, \"\\nModel:\\n\", bioinformatics_history_model)\n",
    "bioinformatics_history_response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Write a paragraph explaining the history of the bioinformatics field.\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nResponse:\\n\", bioinformatics_history_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "179b298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bioinformatics is a relatively young field that has come about as the result of the convergence of several disciplines, including biology, computer science, mathematics, and engineering. It began in the 1970s when scientists first started to use computers to store and analyze biological data. Since then, the field has grown rapidly, as new technologies and techniques have been developed to store and analyze ever larger and more complex data sets. Today, bioinformatics is used in many fields of research, from basic research in genetics and molecular biology, to medical research, to agriculture and food production, to the development of new drugs and therapies. It is becoming increasingly important for research and development in many areas, as our understanding of the complexity of life grows.\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(str(bioinformatics_history_response))['choices'][0]['text'].lstrip('\\n'))\n",
    "# TODO: format properly so that the lines don't break in the middle of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b72df16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nfrom Bio.Seq import Seq\\nfrom Bio.Alphabet import IUPAC\\n\\ndna = Seq(\\\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\\\", IUPAC.unambiguous_dna)\\n\\nprint(dna.translate())\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674253048,\n",
      "  \"id\": \"cmpl-6atzM5mgBQPOxL0AP8jQqO9D53VNA\",\n",
      "  \"model\": \"code-davinci-002\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 71,\n",
      "    \"prompt_tokens\": 21,\n",
      "    \"total_tokens\": 92\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's do some real bioinformatics.\n",
    "translate_to_protein_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nWrite a python script that uses biopython to translate a DNA sequence to protein.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(translate_to_protein_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56aa77ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from Bio.Seq import Seq\n",
      "from Bio.Alphabet import IUPAC\n",
      "\n",
      "dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\", IUPAC.unambiguous_dna)\n",
      "\n",
      "print(dna.translate())\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(str(translate_to_protein_response))['choices'][0]['text'].lstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89f41088",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Bio.Alphabet has been removed from Biopython. In many cases, the alphabet can simply be ignored and removed from scripts. In a few cases, you may need to specify the ``molecule_type`` as an annotation on a SeqRecord for your script to work correctly. Please see https://biopython.org/wiki/Alphabet for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The code doesn't appear to be dangerous, so let's try executing it.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtranslate_to_protein_response\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:2\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.11/site-packages/Bio/Alphabet/__init__.py:20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2000-2002 by Andrew Dalke.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Revisions copyright 2007-2010 by Peter Cock.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Please see the LICENSE file that should have been included as part of this\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# package.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"Alphabets were previously used to declare sequence type and letters (OBSOLETE).\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThe design of Bio.Aphabet included a number of historic design choices\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mtransition from Bio.Alphabet to molecule type annotations.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBio.Alphabet has been removed from Biopython. In many cases, the alphabet can simply be ignored and removed from scripts. In a few cases, you may need to specify the ``molecule_type`` as an annotation on a SeqRecord for your script to work correctly. Please see https://biopython.org/wiki/Alphabet for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: Bio.Alphabet has been removed from Biopython. In many cases, the alphabet can simply be ignored and removed from scripts. In a few cases, you may need to specify the ``molecule_type`` as an annotation on a SeqRecord for your script to work correctly. Please see https://biopython.org/wiki/Alphabet for more information."
     ]
    }
   ],
   "source": [
    "# The code doesn't appear to be dangerous, so let's try executing it.\n",
    "exec(json.loads(str(translate_to_protein_response))['choices'][0]['text'].lstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b18ba12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIVMGR*KGAR*\n"
     ]
    }
   ],
   "source": [
    "# Looks like this code recommendation is obsolete. Maybe we can copy + paste and remove the alphabet bit.\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\")\n",
    "\n",
    "print(dna.translate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb460c2a",
   "metadata": {},
   "source": [
    "Now that is interesting - with a very minor simplification, the code runs properly. One interesting question would be why the AI chose to include a stop codon in the middle of the random sequence it generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c44cbcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nimport sys\\n\\ndef gff2bed(gff_file):\\n    \\\"\\\"\\\"\\n    Convert a GFF3 file to bed format.\\n    \\\"\\\"\\\"\\n    with open(gff_file, 'r') as gff:\\n        for line in gff:\\n            if line.startswith('#'):\\n                continue\\n            else:\\n                line = line.strip().split('\\\\t')\\n                chrom = line[0]\\n                start = line[3]\\n                end = line[4]\\n                name = line[8].split(';')[0].split('=')[1]\\n                strand = line[6]\\n                print(chrom, start, end, name, '0', strand, sep='\\\\t')\\n\\nif __name__ == '__main__':\\n    gff2bed(sys.argv[1])\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1675099154,\n",
      "  \"id\": \"cmpl-6eS6EUFrxrw3hmkIKtzHBcIv5MEUC\",\n",
      "  \"model\": \"code-davinci-002\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 194,\n",
      "    \"prompt_tokens\": 19,\n",
      "    \"total_tokens\": 213\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "convert_gff_to_bed_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nWrite a python script that converts a GFF3 file to bed format.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(convert_gff_to_bed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "342da46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sys\n",
      "\n",
      "def gff2bed(gff_file):\n",
      "    \"\"\"\n",
      "    Convert a GFF3 file to bed format.\n",
      "    \"\"\"\n",
      "    with open(gff_file, 'r') as gff:\n",
      "        for line in gff:\n",
      "            if line.startswith('#'):\n",
      "                continue\n",
      "            else:\n",
      "                line = line.strip().split('\\t')\n",
      "                chrom = line[0]\n",
      "                start = line[3]\n",
      "                end = line[4]\n",
      "                name = line[8].split(';')[0].split('=')[1]\n",
      "                strand = line[6]\n",
      "                print(chrom, start, end, name, '0', strand, sep='\\t')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    gff2bed(sys.argv[1])\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(str(convert_gff_to_bed_response))['choices'][0]['text'].lstrip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ffe2f",
   "metadata": {},
   "source": [
    "This code has some interesting features.\n",
    "1. It is a first-principles example that splits each GFF line on the tabs rather than reading it into a complex data structure with a GFF parser.\n",
    "2. It does not understand that the start coordinate is 1-based in GFF and 0-based in BED, although a slightly different prompt I have tried does understand that.\n",
    "3. It uses the first attribute of GFF column 9 as the BED \"name\" rather than explicitly finding something called \"name\" or \"ID\"; this could be misleading based on the input GFF.\n",
    "4. It does not try to extract the \"score\" from the GFF, but rather just uses 0 for the BED file.\n",
    "5. It chooses to write a 6 column BED file.\n",
    "6. It will not handle blank lines in the GFF.\n",
    "\n",
    "**The biggest problem is that each BED line is going to have an off-by-one error, and this example code is quite dangerous in that way.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ef6ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_openai_response(full_openai_response):\n",
    "    r = json.loads(str(full_openai_response))['choices'][0]['text'].lstrip('\\n')\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3101ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_gff_to_bed_biopython_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nWrite a python script that uses biopython to parse a GFF3 file and uses biopython to format each record in BED format with 0-based start coordinates.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80e97bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sys\n",
      "from Bio import SeqIO\n",
      "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
      "\n",
      "def main(gff_file):\n",
      "    for record in SeqIO.parse(gff_file, \"gff\"):\n",
      "        for feature in record.features:\n",
      "            if feature.type == \"gene\":\n",
      "                print(record.id, feature.location.start, feature.location.end, feature.qualifiers[\"Name\"][0], \".\", feature.strand)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main(sys.argv[1])\n"
     ]
    }
   ],
   "source": [
    "print(first_openai_response(convert_gff_to_bed_biopython_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a382e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nimport sys\\n\\ndef gff2bed(gff_file):\\n    \\\"\\\"\\\"\\n    Convert a GFF3 file to bed format.\\n    \\\"\\\"\\\"\\n    with open(gff_file) as f:\\n        for line in f:\\n            if line.startswith(\\\"#\\\"):\\n                continue\\n            else:\\n                line = line.strip().split(\\\"\\\\t\\\")\\n                chrom = line[0]\\n                start = line[3]\\n                end = line[4]\\n                name = line[8].split(\\\";\\\")[0].split(\\\"=\\\")[1]\\n                print(\\\"\\\\t\\\".join([chrom, start, end, name]))\\n\\nif __name__ == \\\"__main__\\\":\\n    gff2bed(sys.argv[1])\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1675099600,\n",
      "  \"id\": \"cmpl-6eSDQkhq9wPpUFExrNZYteor1ynef\",\n",
      "  \"model\": \"code-davinci-002\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 176,\n",
      "    \"prompt_tokens\": 19,\n",
      "    \"total_tokens\": 195\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "convert_gff_to_bed_shell_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nWrite a bash script that converts a GFF3 file to bed format.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(convert_gff_to_bed_shell_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90728b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sys\n",
      "\n",
      "def gff2bed(gff_file):\n",
      "    \"\"\"\n",
      "    Convert a GFF3 file to bed format.\n",
      "    \"\"\"\n",
      "    with open(gff_file) as f:\n",
      "        for line in f:\n",
      "            if line.startswith(\"#\"):\n",
      "                continue\n",
      "            else:\n",
      "                line = line.strip().split(\"\\t\")\n",
      "                chrom = line[0]\n",
      "                start = line[3]\n",
      "                end = line[4]\n",
      "                name = line[8].split(\";\")[0].split(\"=\")[1]\n",
      "                print(\"\\t\".join([chrom, start, end, name]))\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    gff2bed(sys.argv[1])\n"
     ]
    }
   ],
   "source": [
    "print(first_openai_response(convert_gff_to_bed_shell_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529f5284",
   "metadata": {},
   "source": [
    "Well, that is not ideal - it just wrote a Python script again instead of bash. I wonder if we can get it to use awk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed4f59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_gff_to_bed_shell_2_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nWrite a bash script using awk that converts a GFF3 file to bed format.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6829908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sys\n",
      "import argparse\n",
      "\n",
      "def main(args):\n",
      "    with open(args.input, 'r') as f:\n",
      "        for line in f:\n",
      "            if line.startswith('#'):\n",
      "                continue\n",
      "            line = line.strip().split('\\t')\n",
      "            if line[2] == 'gene':\n",
      "                print('\\t'.join([line[0], line[3], line[4], line[8].split(';')[0].split('=')[1]]))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    parser = argparse.ArgumentParser(description=__doc__)\n",
      "    parser.add_argument('input', help=\"Input GFF3 file\")\n",
      "    args = parser.parse_args()\n",
      "    main(args)\n"
     ]
    }
   ],
   "source": [
    "print(first_openai_response(convert_gff_to_bed_shell_2_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20eccc",
   "metadata": {},
   "source": [
    "Once again, more Python. The documentation does indicate that the code-davinci-002 model is most proficient with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "727c6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioinformatics_coordinates_response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Explain the use of 0-based and 1-based start coordinates in the GFF3 and BED file formats\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad9bc817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nThe GFF3 and BED file formats are used to store genomic feature annotations. Both formats use 0-based start coordinates, meaning the first base of a feature is numbered 0 (e.g. the first base of a gene is 0). This is in contrast to 1-based start coordinates, where the first base of a feature is numbered 1. 0-based start coordinates are typically used in bioinformatic tools and analysis programs, as they are more intuitive for working with arrays, strings, and other numerical data structures.\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1675100566,\n",
      "  \"id\": \"cmpl-6eST0hyLUhX5c8gQ3yuMUY7HiFWYn\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 110,\n",
      "    \"prompt_tokens\": 24,\n",
      "    \"total_tokens\": 134\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(bioinformatics_coordinates_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167a99f",
   "metadata": {},
   "source": [
    "This is incorrect. GFF3 uses 1-based coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d3ad256",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_gff_to_bed_3_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nWrite 3 lines of GFF3 and convert them to BED.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fae0604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sys\n",
      "import os\n",
      "import unittest\n",
      "\n",
      "from pybedtools import BedTool\n",
      "from pybedtools.contrib.gff3 import GFF3_HEADER\n",
      "\n",
      "from . import GFF3_BED_HEADER\n",
      "from . import GFF3_BED_FOOTER\n",
      "from . import GFF3_BED_LINE1\n",
      "from . import GFF3_BED_LINE2\n",
      "from . import GFF3_BED_LINE3\n",
      "from . import GFF3_BED_LINE4\n",
      "from . import GFF3_BED_LINE5\n",
      "from . import GFF3_BED_LINE6\n",
      "from . import GFF3_BED_LINE7\n",
      "from . import GFF3_BED_LINE8\n",
      "from . import GFF3_BED_LINE9\n",
      "from . import GFF3_BED_LINE10\n",
      "from . import GFF3_BED_LINE11\n",
      "from . import GFF3_BED_LINE12\n",
      "from . import GFF3_BED_LINE13\n",
      "from . import GFF3_BED_LINE14\n",
      "from . import GFF3_BED_LINE15\n",
      "from . import GFF3_BED_LINE16\n",
      "from . import GFF3_BED_LINE17\n",
      "from . import GFF3_BED_LINE18\n",
      "from . import GFF3_BED_LINE19\n",
      "from . import GFF3_BED_LINE20\n",
      "from . import GFF3_BED_LINE21\n",
      "from . import GFF3_BED_LINE22\n",
      "from . import GFF3_BED_LINE23\n",
      "from . import GFF3_BED_LINE24\n",
      "from . import GFF3_BED_LINE25\n",
      "from . import GFF3_BED_LINE26\n",
      "from . import GFF3_BED_LINE27\n",
      "from . import GFF3_BED_LINE28\n",
      "from . import GFF3_BED_LINE29\n",
      "from . import GFF3_BED_LINE30\n",
      "from . import GFF3_BED_LINE31\n",
      "from . import GFF3_BED_LINE32\n",
      "from . import GFF3_BED_LINE33\n",
      "from . import GFF3_BED_LINE34\n",
      "from\n"
     ]
    }
   ],
   "source": [
    "print(first_openai_response(convert_gff_to_bed_3_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c005da",
   "metadata": {},
   "source": [
    "That appears to have throughly confused the AI. Perhaps a code model can't fabricate GFF3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c4c546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_protein_sequence_1_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nCreate a protein sequence consisting of length 50 and align to the human genome with python.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=512,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de327c87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import random\n",
      "import re\n",
      "import sys\n",
      "\n",
      "# Create a random protein sequence of length 50\n",
      "protein = \"\"\n",
      "for i in range(50):\n",
      "    protein += random.choice(\"ACDEFGHIKLMNPQRSTVWY\")\n",
      "\n",
      "# Read in the human genome\n",
      "genome = \"\"\n",
      "with open(\"human_genome.txt\", \"r\") as f:\n",
      "    for line in f:\n",
      "        genome += line.strip()\n",
      "\n",
      "# Find all matches of the protein sequence in the genome\n",
      "matches = re.finditer(protein, genome)\n",
      "\n",
      "# Print the locations of the matches\n",
      "for match in matches:\n",
      "    print(match.start())\n"
     ]
    }
   ],
   "source": [
    "print(first_openai_response(align_protein_sequence_1_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "85df595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_protein_sequence_2_response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\nWith Python, create a random protein sequence of length 50 called 'randprot', then use Biopython to read in a FASTA file containing the human genome, then use BLAST to align 'randprot' to the human genome.\\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=912,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c8df3005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from Bio.Blast import NCBIWWW\n",
      "from Bio import SeqIO\n",
      "from Bio.Seq import Seq\n",
      "from Bio.Alphabet import IUPAC\n",
      "import random\n",
      "\n",
      "# Create a random protein sequence of length 50\n",
      "randprot = Seq(\"\".join(random.choice(\"ACDEFGHIKLMNPQRSTVWY\") for i in range(50)), IUPAC.protein)\n",
      "\n",
      "# Read in the human genome\n",
      "human_genome = SeqIO.read(\"human_genome.fasta\", \"fasta\")\n",
      "\n",
      "# Use BLAST to align 'randprot' to the human genome\n",
      "result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", randprot)\n",
      "\n",
      "# Save the output to a file\n",
      "save_file = open(\"my_blast.xml\", \"w\")\n",
      "save_file.write(result_handle.read())\n",
      "save_file.close()\n",
      "result_handle.close()\n"
     ]
    }
   ],
   "source": [
    "print(first_openai_response(align_protein_sequence_2_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8aae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
